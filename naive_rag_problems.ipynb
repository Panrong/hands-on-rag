{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2024-07-02 18:39:05--  https://arxiv.org/pdf/2404.16130\n",
      "Resolving arxiv.org (arxiv.org)... 151.101.67.42, 151.101.131.42, 151.101.3.42, ...\n",
      "Connecting to arxiv.org (arxiv.org)|151.101.67.42|:443... ^C\n",
      "--2024-07-02 18:39:08--  https://arxiv.org/pdf/2310.11511\n",
      "Resolving arxiv.org (arxiv.org)... 151.101.67.42, 151.101.131.42, 151.101.3.42, ...\n",
      "Connecting to arxiv.org (arxiv.org)|151.101.67.42|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 1405127 (1.3M) [application/pdf]\n",
      "Saving to: ‘data/selfrag.pdf’\n",
      "\n",
      "data/selfrag.pdf      4%[                    ]  62.80K  4.86KB/s    eta 4m 30s "
     ]
    }
   ],
   "source": [
    "!wget --user-agent \"Mozilla\" \"https://arxiv.org/pdf/2404.16130\" -O \"data/graphrag.pdf\"\n",
    "!wget --user-agent \"Mozilla\" \"https://arxiv.org/pdf/2310.11511\" -O \"data/selfrag.pdf\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# common configs\n",
    "import os\n",
    "import chromadb\n",
    "from dotenv import load_dotenv\n",
    "from llama_index.core import SimpleDirectoryReader, VectorStoreIndex\n",
    "from llama_index.core.node_parser import SentenceSplitter\n",
    "from llama_index.llms.openai import OpenAI\n",
    "from llama_index.vector_stores.chroma import ChromaVectorStore\n",
    "from llama_index.core import StorageContext, ServiceContext\n",
    "from llama_index.embeddings.openai import OpenAIEmbedding\n",
    "\n",
    "from utils_fn.helpers import print_rag\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "pdf_file_path = \"data/graphrag.pdf\"\n",
    "another_pdf_file_path = \"data/selfrag.pdf\"\n",
    "gpt35_llm = OpenAI(model=\"gpt-3.5-turbo\", api_key=os.environ.get(\"OPENAI_API_KEY\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. RAG is only as good as your data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parsing: most PDF parsing is inadequate\n",
    "documents = SimpleDirectoryReader(input_files=[pdf_file_path]).load_data()\n",
    "\n",
    "with open(\"data/graphrag_simpledirectoryreader.txt\", \"w\") as f:\n",
    "    for document in documents:\n",
    "        f.write(document.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/gz/s8lz9t2967d0t5pjzkg6y5x40000gn/T/ipykernel_1385/4178922555.py:6: DeprecationWarning: Call to deprecated class method from_defaults. (ServiceContext is deprecated, please use `llama_index.settings.Settings` instead.) -- Deprecated since version 0.10.0.\n",
      "  service_context = ServiceContext.from_defaults(embed_model=OpenAIEmbedding())\n"
     ]
    }
   ],
   "source": [
    "# chunking and embedding: many paramenters to optimize\n",
    "db = chromadb.PersistentClient(path=\"data/chroma_db\")\n",
    "chroma_collection = db.get_or_create_collection(\"graphrag\")\n",
    "vector_store = ChromaVectorStore(chroma_collection=chroma_collection)\n",
    "storage_context = StorageContext.from_defaults(vector_store=vector_store)\n",
    "service_context = ServiceContext.from_defaults(embed_model=OpenAIEmbedding())\n",
    "\n",
    "index = VectorStoreIndex.from_documents(\n",
    "    documents,\n",
    "    transformations=[SentenceSplitter(chunk_size=256, chunk_overlap=0)],\n",
    "    storage_context=storage_context,\n",
    "    service_context=service_context\n",
    ")\n",
    "\n",
    "index.storage_context.persist(\"data/chroma_db/graphrag\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0m\n",
      "\u001b[34m\u001b[1m  You can now view your Streamlit app in your browser.\u001b[0m\n",
      "\u001b[0m\n",
      "\u001b[34m  Local URL: \u001b[0m\u001b[1mhttp://localhost:8501\u001b[0m\n",
      "\u001b[34m  Network URL: \u001b[0m\u001b[1mhttp://30.222.192.144:8501\u001b[0m\n",
      "\u001b[0m\n",
      "\u001b[34m\u001b[1m  For better performance, install the Watchdog module:\u001b[0m\n",
      "\n",
      "  $ xcode-select --install\n",
      "  $ pip install watchdog\n",
      "            \u001b[0m\n",
      "Opening database: data/chroma_db\n",
      "Opening database: data/chroma_db\n",
      "^C\n",
      "\u001b[34m  Stopping...\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "! streamlit run utils_fn/view_chroma.py \"data/chroma_db\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Questions where rag will fail"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 Query one PDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = SimpleDirectoryReader(input_files=[pdf_file_path]).load_data()\n",
    "index = VectorStoreIndex.from_documents(\n",
    "    documents,\n",
    "    transformations=[SentenceSplitter(chunk_size=256, chunk_overlap=0)]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[92mQuestion:\n",
      "\u001b[0mGive me a summary of main points in Discussion Section\n",
      "\n",
      "\u001b[92mRetrieved:\n",
      "\u001b[0mNode ID: 27b14c99-9c5f-4798-894d-42a32c041798\n",
      "Text: For example, a user may scan through community summaries at one\n",
      "level looking for general themes of interest, then follow links to the\n",
      "reports at the lower level that provide more details for each of the\n",
      "subtopics. Here, however, we focus on their utility as part of a\n",
      "graph-based index used for answering global queries. Community\n",
      "summaries are g...\n",
      "Score:  0.794\n",
      "\n",
      "\n",
      "Node ID: e71528e5-433d-43b8-8f6d-40847210147a\n",
      "Text: The prioritization is as follows: for each community edge in\n",
      "decreasing order of combined source and target node degree (i.e.,\n",
      "overall prominance), add descriptions of the source node, target node,\n",
      "linked covariates, and the edge itself. •Higher-level communities . If\n",
      "all element summaries fit within the token limit of the con- text\n",
      "window, proc...\n",
      "Score:  0.784\n",
      "\n",
      "\n",
      "Node ID: 72fe94ac-6f8d-4405-96ef-85e31f209d96\n",
      "Text: This approach allows us to use larger chunk sizes without a drop\n",
      "in quality (Figure 2) or the forced introduction of noise. 2.3 Element\n",
      "Instances →Element Summaries The use of an LLM to “extract”\n",
      "descriptions of entities, relationships, and claims represented in\n",
      "source texts is already a form of abstractive summarization, relying\n",
      "on the LLM to c...\n",
      "Score:  0.779\n",
      "\n",
      "\n",
      "Node ID: d60dc66c-7ea2-45fa-bdea-64c3f38687a2\n",
      "Text: Dataset Example activity framing and generation of global\n",
      "sensemaking questions Podcast transcriptsUser : A tech journalist\n",
      "looking for insights and trends in the tech industry Task:\n",
      "Understanding how tech leaders view the role of policy and regulation\n",
      "Questions : 1. Which episodes deal primarily with tech policy and\n",
      "government regulation? 2. Ho...\n",
      "Score:  0.779\n",
      "\n",
      "\n",
      "Node ID: 98407469-7b42-4857-974c-fc891e08cec9\n",
      "Text: “a motivated, continuous effort to understand connections (which\n",
      "can be among people, places, and events) in order to anticipate their\n",
      "trajectories and act effectively ” (Klein et al., 2006a). Supporting\n",
      "human-led sensemaking over entire text corpora, however, needs a way\n",
      "for people to both apply and refine their mental model of the data\n",
      "(Klein ...\n",
      "Score:  0.777\n",
      "\n",
      "\n",
      "\u001b[92mAnswer:\n",
      "\u001b[0mThe discussion section highlights the use of community summaries for answering global queries efficiently. It explains the process of generating community summaries based on node degrees and token limits. Additionally, it discusses the hierarchical structure of community summaries and how they can be utilized to provide answers to user queries. The section also touches upon the abstractive summarization process using LLMs to extract meaningful summaries from source texts and the potential challenges related to duplicate entity elements.\n"
     ]
    }
   ],
   "source": [
    "# summarization\n",
    "print_rag(index, \"Give me a summary of main points in Discussion Section\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The text discusses the limitations of the evaluation approach used, suggesting that more work is needed to understand performance variations across different types of questions, data, and dataset sizes. It also mentions the potential benefits of comparing fabrication rates using approaches like SelfCheckGPT. The text also highlights the trade-offs of building a graph index, noting that while Graph RAG consistently performed well, a graph-free approach to summarization was competitive in some cases. The decision to invest in a graph index depends on factors such as compute budget and expected number of queries. Future work could involve refining the current Graph RAG approach, exploring local matching of user queries and graph annotations, and implementing hybrid RAG schemes. Additionally, the text suggests extending the \"roll-up\" operation across more levels of the community hierarchy and implementing a more exploratory \"drill down\" mechanism.\n"
     ]
    }
   ],
   "source": [
    "discussion_text = \"\"\"5 Discussion\n",
    "Limitations of evaluation approach . Our evaluation to date has only examined a certain class of\n",
    "sensemaking questions for two corpora in the region of 1 million tokens. More work is needed\n",
    "to understand how performance varies across different ranges of question types, data types, and\n",
    "dataset sizes, as well as to validate our sensemaking questions and target metrics with end users.\n",
    "Comparison of fabrication rates, e.g., using approaches like SelfCheckGPT (Manakul et al., 2023),\n",
    "would also improve on the current analysis.\n",
    "Trade-offs of building a graph index . We consistently observed Graph RAG achieve the best head-\n",
    "to-head results against other methods, but in many cases the graph-free approach to global summa-\n",
    "rization of source texts performed competitively. The real-world decision about whether to invest in\n",
    "building a graph index depends on multiple factors, including the compute budget, expected number\n",
    "of lifetime queries per dataset, and value obtained from other aspects of the graph index (including\n",
    "the generic community summaries and the use of other graph-related RAG approaches).\n",
    "Future work . The graph index, rich text annotations, and hierarchical community structure support-\n",
    "ing the current Graph RAG approach offer many possibilities for refinement and adaptation. This\n",
    "includes RAG approaches that operate in a more local manner, via embedding-based matching of\n",
    "user queries and graph annotations, as well as the possibility of hybrid RAG schemes that combine\n",
    "embedding-based matching against community reports before employing our map-reduce summa-\n",
    "rization mechanisms. This “roll-up” operation could also be extended across more levels of the\n",
    "community hierarchy, as well as implemented as a more exploratory “drill down” mechanism that\n",
    "follows the information scent contained in higher-level community summaries.\n",
    "\"\"\"\n",
    "\n",
    "print(gpt35_llm.complete(f\"Give me a summary of main points of following text: \\n {discussion_text}\").text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[92mQuestion:\n",
      "\u001b[0mCompare the advantages and disadvantages of the proposed method with traditional RAG\n",
      "\n",
      "\u001b[92mRetrieved:\n",
      "\u001b[0mNode ID: 50fb98bf-e2ff-441c-9ed5-a87890072a7d\n",
      "Text: Empowerment comparisons showed mixed results for both global\n",
      "approaches versus na¨ıve RAG ( SS) and Graph RAG approaches versus\n",
      "source text summarization ( TS). Ad-hoc LLM use to analyze LLM\n",
      "reasoning for this measure indicated that the ability to provide\n",
      "specific exam- ples, quotes, and citations was judged to be key to\n",
      "helping users reach an i...\n",
      "Score:  0.849\n",
      "\n",
      "\n",
      "Node ID: 59ac5174-217d-46b0-a9c4-4cd58f058779\n",
      "Text: Comparison of fabrication rates, e.g., using approaches like\n",
      "SelfCheckGPT (Manakul et al., 2023), would also improve on the current\n",
      "analysis. Trade-offs of building a graph index . We consistently\n",
      "observed Graph RAG achieve the best head- to-head results against\n",
      "other methods, but in many cases the graph-free approach to global\n",
      "summa- rization o...\n",
      "Score:  0.835\n",
      "\n",
      "\n",
      "Node ID: 0c8dbdb2-d3fb-4922-ab3d-f4586c3a7718\n",
      "Text: More advanced variations exist, but all solve the problem of\n",
      "what to do when an external dataset of interest exceeds the LLM’s\n",
      "context window. Advanced RAG systems include pre-retrieval, retrieval,\n",
      "post-retrieval strategies designed to over- come the drawbacks of Na\n",
      "¨ıve RAG, while Modular RAG systems include patterns for iterative and\n",
      "dynamic c...\n",
      "Score:  0.832\n",
      "\n",
      "\n",
      "Node ID: eb88f4a1-2a3c-422b-80f9-c6d8bba96956\n",
      "Text: na ¨ıve RAG . As shown in Figure 4, global approaches\n",
      "consistently out- performed the na ¨ıve RAG ( SS) approach in both\n",
      "comprehensiveness and diversity metrics across datasets. Specifically,\n",
      "global approaches achieved comprehensiveness win rates between 72-83%\n",
      "for Podcast transcripts and 72-80% for News articles, while diversity\n",
      "win rates range...\n",
      "Score:  0.832\n",
      "\n",
      "\n",
      "Node ID: 2435d220-f65d-4acb-af9e-97f43fed9946\n",
      "Text: Prior QFS methods, meanwhile, fail to scale to the quantities of\n",
      "text indexed by typical RAG systems. To combine the strengths of these\n",
      "contrasting methods, we propose a Graph RAG approach to question\n",
      "answering over private text corpora that scales with both the\n",
      "generality of user questions and the quantity of source text to be in-\n",
      "dexed. Our ap...\n",
      "Score:  0.831\n",
      "\n",
      "\n",
      "\u001b[92mAnswer:\n",
      "\u001b[0mThe proposed Graph RAG method offers advantages such as improved comprehensiveness and diversity of generated answers compared to traditional RAG methods. It also scales well with the generality of user questions and the quantity of source text to be indexed. However, building a graph index may require more computational resources and may not always outperform graph-free approaches in global summarization of source texts. The decision to invest in building a graph index depends on factors like compute budget, expected number of queries, and the value obtained from other aspects of the graph index.\n"
     ]
    }
   ],
   "source": [
    "# comparision\n",
    "print_rag(index, \"Compare the advantages and disadvantages of the proposed method with traditional RAG\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[92mQuestion:\n",
      "\u001b[0mcompare the results generated by Graph RAG and Naive RAG in Table 2\n",
      "\n",
      "\u001b[92mRetrieved:\n",
      "\u001b[0mNode ID: eb88f4a1-2a3c-422b-80f9-c6d8bba96956\n",
      "Text: na ¨ıve RAG . As shown in Figure 4, global approaches\n",
      "consistently out- performed the na ¨ıve RAG ( SS) approach in both\n",
      "comprehensiveness and diversity metrics across datasets. Specifically,\n",
      "global approaches achieved comprehensiveness win rates between 72-83%\n",
      "for Podcast transcripts and 72-80% for News articles, while diversity\n",
      "win rates range...\n",
      "Score:  0.860\n",
      "\n",
      "\n",
      "Node ID: 56ff2d23-c43f-475e-be96-1aaff2a3f096\n",
      "Text: Answer 1, while comprehensive, includes a lot of detailed\n",
      "information about various figures in different sectors of\n",
      "entertainment, which, while informative, does not directly answer the\n",
      "question with the same level of conciseness and specificity as Answer\n",
      "2. Table 2: Example question for the News article dataset, with\n",
      "generated answers from Grap...\n",
      "Score:  0.848\n",
      "\n",
      "\n",
      "Node ID: 50fb98bf-e2ff-441c-9ed5-a87890072a7d\n",
      "Text: Empowerment comparisons showed mixed results for both global\n",
      "approaches versus na¨ıve RAG ( SS) and Graph RAG approaches versus\n",
      "source text summarization ( TS). Ad-hoc LLM use to analyze LLM\n",
      "reasoning for this measure indicated that the ability to provide\n",
      "specific exam- ples, quotes, and citations was judged to be key to\n",
      "helping users reach an i...\n",
      "Score:  0.843\n",
      "\n",
      "\n",
      "Node ID: e169a80c-50ca-4275-b511-65fe313c463c\n",
      "Text: When comparing community summaries to source texts using Graph\n",
      "RAG, community summaries generally provided a small but consistent\n",
      "improvement in answer comprehensiveness and diversity, except for\n",
      "root-level summaries. Intermediate-level summaries in the Podcast\n",
      "dataset and low-level community summaries in the News dataset achieved\n",
      "comprehensiven...\n",
      "Score:  0.841\n",
      "\n",
      "\n",
      "Node ID: e4d7a545-9ce1-4be7-9e49-1992742ee3a4\n",
      "Text: percentages of (row condition) over (column condition) across\n",
      "two datasets, four metrics, and 125 questions per comparison (each\n",
      "repeated five times and averaged). The overall winner per dataset and\n",
      "metric is shown in bold. Self-win rates were not computed but are\n",
      "shown as the expected 50% for reference. All Graph RAG conditions\n",
      "outperformed na ...\n",
      "Score:  0.840\n",
      "\n",
      "\n",
      "\u001b[92mAnswer:\n",
      "\u001b[0mGraph RAG outperformed Naive RAG in terms of answer comprehensiveness and diversity in Table 2.\n"
     ]
    }
   ],
   "source": [
    "print_rag(index, \"compare the results generated by Graph RAG and Naive RAG in Table 2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[92mQuestion:\n",
      "\u001b[0mTell me about the drawbacks about RAG, and tell me about existing methods in advanced RAG, and then generate your own conclusion about the unique contribution of the proposed method.\n",
      "\n",
      "\u001b[92mRetrieved:\n",
      "\u001b[0mNode ID: 0c8dbdb2-d3fb-4922-ab3d-f4586c3a7718\n",
      "Text: More advanced variations exist, but all solve the problem of\n",
      "what to do when an external dataset of interest exceeds the LLM’s\n",
      "context window. Advanced RAG systems include pre-retrieval, retrieval,\n",
      "post-retrieval strategies designed to over- come the drawbacks of Na\n",
      "¨ıve RAG, while Modular RAG systems include patterns for iterative and\n",
      "dynamic c...\n",
      "Score:  0.846\n",
      "\n",
      "\n",
      "Node ID: 50fb98bf-e2ff-441c-9ed5-a87890072a7d\n",
      "Text: Empowerment comparisons showed mixed results for both global\n",
      "approaches versus na¨ıve RAG ( SS) and Graph RAG approaches versus\n",
      "source text summarization ( TS). Ad-hoc LLM use to analyze LLM\n",
      "reasoning for this measure indicated that the ability to provide\n",
      "specific exam- ples, quotes, and citations was judged to be key to\n",
      "helping users reach an i...\n",
      "Score:  0.839\n",
      "\n",
      "\n",
      "Node ID: 2435d220-f65d-4acb-af9e-97f43fed9946\n",
      "Text: Prior QFS methods, meanwhile, fail to scale to the quantities of\n",
      "text indexed by typical RAG systems. To combine the strengths of these\n",
      "contrasting methods, we propose a Graph RAG approach to question\n",
      "answering over private text corpora that scales with both the\n",
      "generality of user questions and the quantity of source text to be in-\n",
      "dexed. Our ap...\n",
      "Score:  0.832\n",
      "\n",
      "\n",
      "Node ID: 59ac5174-217d-46b0-a9c4-4cd58f058779\n",
      "Text: Comparison of fabrication rates, e.g., using approaches like\n",
      "SelfCheckGPT (Manakul et al., 2023), would also improve on the current\n",
      "analysis. Trade-offs of building a graph index . We consistently\n",
      "observed Graph RAG achieve the best head- to-head results against\n",
      "other methods, but in many cases the graph-free approach to global\n",
      "summa- rization o...\n",
      "Score:  0.830\n",
      "\n",
      "\n",
      "Node ID: 2def7672-c323-4c42-ab7c-2f4d98553f76\n",
      "Text: For the target qualities of comprehensiveness, diver- sity, and\n",
      "empowerment (defined in subsection 3.4) that develop understanding of\n",
      "broad issues and themes, we both explore the impact of varying the the\n",
      "hierarchical level of community summaries used to answer queries, as\n",
      "well as compare to na ¨ıve RAG and global map-reduce summarization of\n",
      "sou...\n",
      "Score:  0.828\n",
      "\n",
      "\n",
      "\u001b[92mAnswer:\n",
      "\u001b[0mThe drawbacks of Naïve RAG include limitations in handling external datasets that exceed the context window of the language model. Advanced RAG systems address these drawbacks through strategies like pre-retrieval, retrieval, and post-retrieval techniques. Modular RAG systems incorporate patterns for iterative and dynamic cycles of retrieval and generation to enhance performance.\n",
      "\n",
      "The proposed Graph RAG method introduces a unique contribution by utilizing a graph-based text index that scales effectively with both the generality of user questions and the quantity of source text to be indexed. This approach involves building an entity knowledge graph from source documents and generating community summaries for closely-related entities. These summaries are then used to provide comprehensive and diverse responses to user queries, showcasing substantial improvements over Naïve RAG baselines. The method's ability to combine the strengths of different approaches while offering efficient question answering over private text corpora makes it a promising advancement in the field of RAG systems.\n"
     ]
    }
   ],
   "source": [
    "# General Multi-part Question\n",
    "print_rag(index, \"Tell me about the drawbacks about RAG, and tell me about existing methods in advanced RAG, and then generate your own conclusion about the unique contribution of the proposed method.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Query two PDFs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "twp_documents = SimpleDirectoryReader(input_files=[pdf_file_path, another_pdf_file_path]).load_data()\n",
    "two_doc_index = VectorStoreIndex.from_documents(\n",
    "    twp_documents,\n",
    "    transformations=[SentenceSplitter(chunk_size=256, chunk_overlap=0)]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[92mQuestion:\n",
      "\u001b[0mCompare the advantages and disadvantages of Graph RAG with Self-RAG\n",
      "\n",
      "\u001b[92mRetrieved:\n",
      "\u001b[0mNode ID: de337a7b-7bf1-4502-9c93-5cf68959997f\n",
      "Text: Comparison of fabrication rates, e.g., using approaches like\n",
      "SelfCheckGPT (Manakul et al., 2023), would also improve on the current\n",
      "analysis. Trade-offs of building a graph index . We consistently\n",
      "observed Graph RAG achieve the best head- to-head results against\n",
      "other methods, but in many cases the graph-free approach to global\n",
      "summa- rization o...\n",
      "Score:  0.864\n",
      "\n",
      "\n",
      "Node ID: 66e17277-c312-4713-89ae-b48b0680045e\n",
      "Text: Empowerment comparisons showed mixed results for both global\n",
      "approaches versus na¨ıve RAG ( SS) and Graph RAG approaches versus\n",
      "source text summarization ( TS). Ad-hoc LLM use to analyze LLM\n",
      "reasoning for this measure indicated that the ability to provide\n",
      "specific exam- ples, quotes, and citations was judged to be key to\n",
      "helping users reach an i...\n",
      "Score:  0.858\n",
      "\n",
      "\n",
      "Node ID: 768b0b36-b44d-44bd-8e7d-c9d419815ca6\n",
      "Text: More advanced variations exist, but all solve the problem of\n",
      "what to do when an external dataset of interest exceeds the LLM’s\n",
      "context window. Advanced RAG systems include pre-retrieval, retrieval,\n",
      "post-retrieval strategies designed to over- come the drawbacks of Na\n",
      "¨ıve RAG, while Modular RAG systems include patterns for iterative and\n",
      "dynamic c...\n",
      "Score:  0.857\n",
      "\n",
      "\n",
      "Node ID: 72c0610d-0851-4ae0-9e26-36f792f86bbb\n",
      "Text: When comparing community summaries to source texts using Graph\n",
      "RAG, community summaries generally provided a small but consistent\n",
      "improvement in answer comprehensiveness and diversity, except for\n",
      "root-level summaries. Intermediate-level summaries in the Podcast\n",
      "dataset and low-level community summaries in the News dataset achieved\n",
      "comprehensiven...\n",
      "Score:  0.853\n",
      "\n",
      "\n",
      "Node ID: 794e6599-a498-4fc6-88c3-1ddbb697f0d7\n",
      "Text: Prior QFS methods, meanwhile, fail to scale to the quantities of\n",
      "text indexed by typical RAG systems. To combine the strengths of these\n",
      "contrasting methods, we propose a Graph RAG approach to question\n",
      "answering over private text corpora that scales with both the\n",
      "generality of user questions and the quantity of source text to be in-\n",
      "dexed. Our ap...\n",
      "Score:  0.852\n",
      "\n",
      "\n",
      "\u001b[92mAnswer:\n",
      "\u001b[0mGraph RAG offers advantages such as achieving the best results in head-to-head comparisons against other methods, providing efficient and comprehensive question answering, and scalability advantages in terms of context token requirements. On the other hand, the decision to invest in building a graph index depends on factors like compute budget, expected number of queries per dataset, and the value obtained from other aspects of the graph index.\n"
     ]
    }
   ],
   "source": [
    "# comparision\n",
    "print_rag(two_doc_index, \"Compare the advantages and disadvantages of Graph RAG with Self-RAG\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[92mQuestion:\n",
      "\u001b[0mTell me about the drawbacks of Graph RAG, and tell me about advantages of Self-RAG, and then generate your own conclusion about the relationship of the two methods.\n",
      "\n",
      "\u001b[92mRetrieved:\n",
      "\u001b[0mNode ID: 768b0b36-b44d-44bd-8e7d-c9d419815ca6\n",
      "Text: More advanced variations exist, but all solve the problem of\n",
      "what to do when an external dataset of interest exceeds the LLM’s\n",
      "context window. Advanced RAG systems include pre-retrieval, retrieval,\n",
      "post-retrieval strategies designed to over- come the drawbacks of Na\n",
      "¨ıve RAG, while Modular RAG systems include patterns for iterative and\n",
      "dynamic c...\n",
      "Score:  0.852\n",
      "\n",
      "\n",
      "Node ID: de337a7b-7bf1-4502-9c93-5cf68959997f\n",
      "Text: Comparison of fabrication rates, e.g., using approaches like\n",
      "SelfCheckGPT (Manakul et al., 2023), would also improve on the current\n",
      "analysis. Trade-offs of building a graph index . We consistently\n",
      "observed Graph RAG achieve the best head- to-head results against\n",
      "other methods, but in many cases the graph-free approach to global\n",
      "summa- rization o...\n",
      "Score:  0.852\n",
      "\n",
      "\n",
      "Node ID: 66e17277-c312-4713-89ae-b48b0680045e\n",
      "Text: Empowerment comparisons showed mixed results for both global\n",
      "approaches versus na¨ıve RAG ( SS) and Graph RAG approaches versus\n",
      "source text summarization ( TS). Ad-hoc LLM use to analyze LLM\n",
      "reasoning for this measure indicated that the ability to provide\n",
      "specific exam- ples, quotes, and citations was judged to be key to\n",
      "helping users reach an i...\n",
      "Score:  0.847\n",
      "\n",
      "\n",
      "Node ID: 794e6599-a498-4fc6-88c3-1ddbb697f0d7\n",
      "Text: Prior QFS methods, meanwhile, fail to scale to the quantities of\n",
      "text indexed by typical RAG systems. To combine the strengths of these\n",
      "contrasting methods, we propose a Graph RAG approach to question\n",
      "answering over private text corpora that scales with both the\n",
      "generality of user questions and the quantity of source text to be in-\n",
      "dexed. Our ap...\n",
      "Score:  0.846\n",
      "\n",
      "\n",
      "Node ID: 3d6cb422-8f44-417c-a028-5bd87e939480\n",
      "Text: 3 71.3 5 R ESULTS AND ANALYSIS 5.1 M AINRESULTS Comparison\n",
      "against baselines without retrieval. Table 2 (top) presents the\n",
      "baselines without retrieval. Our SELF-RAG(bottom two rows)\n",
      "demonstrates a substantial performance advantage over supervised fine-\n",
      "tuned LLMs in all tasks and even outperforms ChatGPT in PubHealth,\n",
      "PopQA, biography generations...\n",
      "Score:  0.840\n",
      "\n",
      "\n",
      "\u001b[92mAnswer:\n",
      "\u001b[0mThe drawbacks of Graph RAG include the challenge of handling external datasets that exceed the context window of the LLM, which can limit the system's ability to effectively retrieve and generate information. On the other hand, Self-RAG demonstrates advantages such as substantial performance advantages over supervised fine-tuned LLMs in various tasks, outperforming existing RAG models in many instances.\n",
      "\n",
      "In conclusion, Graph RAG faces limitations related to managing large external datasets, while Self-RAG shows superior performance compared to other models in various tasks. The two methods offer different strengths and weaknesses, with Graph RAG focusing on handling external data efficiently and Self-RAG excelling in performance metrics. Combining aspects of both approaches could potentially lead to a more comprehensive and effective question-answering system that leverages the strengths of each method.\n"
     ]
    }
   ],
   "source": [
    "# General Multi-part Question\n",
    "print_rag(two_doc_index, \"Tell me about the drawbacks of Graph RAG, and tell me about advantages of Self-RAG, and then generate your own conclusion about the relationship of the two methods.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d323e23ecf50b1bd7b382de0c28c32b259dcb0f82ab398c59f13382954f7cc88"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
